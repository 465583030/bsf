------------------------- STUDY --------------------------------
Study shadow rendering implementations
Study how is transparency handled (is it order independant?)
Figure out what is skylight
Determine how is light bleeding handled (if at all)

---------------------- IMPLEMENTATION ---------------------------

RenderTexturePool needs support for cube and 3D textures
Lights need getLightMesh() method
 - Need cone to use when rendering spot light, sphere otherwise
Load up and set up a test-bed with Ribek's scene
Quantize buffer sizes so they're divideable by 8 when requesting them from RenderTexturePool

R11G11B10 and R10G10B10A2 formats haven't been tested

Make sure materials can generate unique "hash" values so I can quickly check if they're equal
 - Generate unique ID for each shader (32bit)
 - Limit state IDs to 10 bits
 - Generate a combined 64bit hash value for the material using shader + 3 states

Make GUI and Overlay render separately without using the main render queue
 - Get rid of DrawList and make them render similar to how handles/gizmos do it
 - They should render after everything else
 - Disable depth test and depth write in their material
 - Since most GUI elements share a material check if material changed from the last element and don't set new shaders/states otherwise
   - (changing params and param buffers should still apply)
   - Since I'm doing the rendering directly in GUIManager I can exactly control which states I modify

Make scene grid rendering more akin to handle & gizmo rendering so I can remove the onRenderViewport callback
 - Similar thing with dock manager

Add material flag "transparent". 
 - Priority is always applied within its transparent/opaque queue. Priority and sort order are kept as is. 
 - Transparent flag just determines the rendering method. Later I can probably also add "animated" and similar.
 - Depending on set flag populate two different render queues per camera (+ a special render queue for GUI and overlay)

Rendering procedure should be:
 - For each camera go over each renderable and determine if their layers match
 - If they match do frustum culling
 - Add renderables to opaque or transparent queue depending on material
 - This should happen in renderAllCore before actual rendering starts
 - When rendering bind gbuffer render targets and render opaque queue
 - Unbind gbuffer and resolve to scene color
 - Bind scene color and render transparent queue
 - Resolve scene color to frame buffer (they could be the same target if no MSAA is used, and gamma correction is properly set)
 - After rendering is done make sure to clear the queues so I don't hold invalid references

Reduce state switching:
 - Extend render queues so they compare material hash values and sort accordingly
 - Add a flag that allows me to control whether the queue should prefer distance sort or material sort
 - Extend entries output from render queue with a flag that signals that a material should be re-applied
 - When rendering only apply new shaders & states when that flag is encountered
 - Switch buffers, textures and sampler for each renderable (possibly ignoring static/per-frame/per-camera ones)

Store RenderTargets per camera
 - Only create it if camera is rendering some renderables
 - If none are rendered clear the reference to free the targets

Generate different RenderableController for each set of elements
 - Will likely want to rename current LitTexRenderableController to OpaqueSomething
 - Each controller would be connected to its own render queue (generated in above step)
 - Renderable controller should probably be notified when rendering starts/ends so it may bind gbuffer and/or other resoures.

Light queues:
 - Will likely need to generate a set of visible lights per camera similar to renderables (separate them by type most likely)
 - Will also need a set of renderables per light when rendering shadows

--------------------------- DESIGN ---------------------------

Issue with state caching: State caching doesn't work when deserializing

How will cameras interact with the renderer? The cameras currently available shouldn't have depth buffers
 - Need to modify RenderWindow so it doesn't create depth buffers
  - Find all places where I create windows and modify this
  - Modify render target creation in SceneWindow
 - What happens when a user creates a camera with a depth buffer?
   - Print out a warning and ignore it?
   - Or resolve the gbuffer into it? Probably this, as I want to be able to read the depth buffer from script code if needed
     - This still isn't perfect as I'd have duplicate buffers when using non-MSAA buffer that require no resolve
 - Similar issue when a multisampled buffer is used for the camera

Separate GUI rendering into a separate part to be rendered after gbuffer is resolved?

Will likely need an easy way to determine supported feature set (likely just depending on shader model)

Consider encapsulating shaders together with methods for setting their parameters (and possibly retrieving output)
 - So that external code doesn't need to know about its internal and do less work
 - This would contain a reference to the shader and its parameters
 - It would then have a SetParameters method (custom per each shader) which updates its params in a simple manner
 - (Later) Possibly allow them to return a feature level and/or platform they're to be used on
 - (Later) It might be important to be easily able to use different versions of the shader (e.g. different defines)
   - This might require handling compilation on this class, instead on resource load (But then again I could potentially
     have the shader in an include file and then specific shader files for each define version)

--------------------------- LONG TERM ------------------------

Deferred:
 - Create a tile deferred renderer
 - Support for point, directional and spot lights
 - Basic lambert shading initially
  - Create brand new default shaders
 - HDR, tone mapping and gamma correct (toggle-able)
   - Will likely need a simple framework for rendering full-screen effects
     (e.g. I will need to downsample scene to determine brightness here, but will
      also need that framework for all post-processing)

Implement shadows
 - Start with hard shadows
 - Move to PCF soft shadows (see if there's anything better)
 - Then cascaded maps

Later: 
 - Reflection probes
 - Proper PBR materials with reflection
 - Post-processing system - FXAA, SSAO, Color correction, Depth of field (Bokeh)
 - Forward rendering for transparent objects
 - Occlusion
 - GI
 - Volumetric lighting
 - SSR
 - Depth pre-pass - Make sure this can be toggled on and off as needed
 - HDR skybox, skylight stuff
 - Skin & vegetation shaders
 - Tesselation/displacement/parallax
 - Water
 - Fog
 - Motion blur
 - Per object shadows
 - Extend camera with shutter speed (motion blur), aperture size and focal distance (depth of field), exposure (HDR)
--------------------------- TEST -----------------------------

Test all APIs with new changes regarding depth buffer creation on windows