------------------------- STUDY --------------------------------
Study shadow rendering implementations
Study how is transparency handled (is it order independant?)
Figure out what is skylight
Determine how is light bleeding handled (if at all)

---------------------- IMPLEMENTATION ---------------------------

RenderTexturePool needs support for cube and 3D textures
Lights need getLightMesh() method
 - Need cone to use when rendering spot light, sphere otherwise
Load up and set up a test-bed with Ribek's scene
Quantize buffer sizes so they're divideable by 8 when requesting them from RenderTexturePool

Keep a list of all renderables per camera depending on their layer
 - This would be an optimization so I don't need to filter them every frame
 - I'd need to update this list when renderable is added/removed, when camera is added/removed and when layer is changed (camera's or renderable's)

Before any rendering is done generate separate render queues for all elements
 - Iterate over all elements valid for the camera and perform frustum culling
 - Initially this would be different queues for transparent & opaque, but later there might be more types
 - Store these queues per-camera
 - Do the same for lights (separate them by type most likely)
 - Later:
  - Extend render queues so they also sort by material (if needed, it should be easy to change sort order)
  - Materials should be transformed into a set of material diffs (e.g. only set new shader, buffer, texture or cbuffer
    if they don't match the previous material)
	 - i.e. some elements in the render queue would be renderable elements (with no material info) and others
	   would be material diffs that change the state

Generate different RenderableController for each set of elements
 - Will likely want to rename current LitTexRenderableController to OpaqueSomething
 - Each controller would be connected to its own render queue (generated in above step)
 - Renderable controller should probably be notified when rendering starts/ends so it may bind gbuffer and/or other resoures.

Create a class RenderTargets
 - ::create(CameraPtr)
 - ::bind (calls RenderTargetPool::get() and sets the render targets)
 - ::unbind (calls RenderTargetPool::free)
 - Holds references to PooledRenderTarget

Store RenderTargets per camera
 - Only create it if camera is rendering some renderables
 - If none are rendered clear the reference to free the targets

I sort rendering based on render targets so I don't need to rebind them
 - I should do something similar with GBuffers
 - First sort by GBuffers, then sort by output render targets
 - This means I'll need to find out what kind of gbuffers cameras need before rendering the camera
   - Move the renderable by layer filtering in renderAll, or do it when renderers are updated (as described above)
   - Don't actually allocate targets at this point to avoid allocating a lot of memory at once.

--------------------------- DESIGN ---------------------------

Issue with state caching: State caching doesn't work when deserializing

How will cameras interact with the renderer? The cameras currently available shouldn't have depth buffers
 - Need to modify RenderWindow so it doesn't create depth buffers
  - Find all places where I create windows and modify this
  - Modify render target creation in SceneWindow
 - What happens when a user creates a camera with a depth buffer?
   - Print out a warning and ignore it?
   - Or resolve the gbuffer into it? Probably this, as I want to be able to read the depth buffer from script code if needed
     - This still isn't perfect as I'd have duplicate buffers when using non-MSAA buffer that require no resolve
 - Similar issue when a multisampled buffer is used for the camera

Separate GUI rendering into a separate part to be rendered after gbuffer is resolved?

Will likely need an easy way to determine supported feature set (likely just depending on shader model)
Consider encapsulating shaders together with methods for setting their parameters (and possibly retrieving output)
 - So that external code doesn't need to know about its internal and do less work
 - This would contain a reference to the shader and its parameters
 - It would then have a SetParameters method (custom per each shader) which updates its params in a simple manner
 - (Later) Possibly allow them to return a feature level and/or platform they're to be used on
 - (Later) It might be important to be easily able to use different versions of the shader (e.g. different defines)
   - This might require handling compilation on this class, instead on resource load (But then again I could potentially
     have the shader in an include file and then specific shader files for each define version)

--------------------------- LONG TERM ------------------------

Deferred:
 - Create a tile deferred renderer
 - Support for point, directional and spot lights
 - Basic lambert shading initially
  - Create brand new default shaders
 - HDR, tone mapping and gamma correct (toggle-able)
   - Will likely need a simple framework for rendering full-screen effects
     (e.g. I will need to downsample scene to determine brightness here, but will
      also need that framework for all post-processing)

Implement shadows
 - Start with hard shadows
 - Move to PCF soft shadows (see if there's anything better)
 - Then cascaded maps

Later: 
 - Reflection probes
 - Proper PBR materials with reflection
 - Post-processing system - FXAA, SSAO, Color correction, Depth of field (Bokeh)
 - Forward rendering for transparent objects
 - Occlusion
 - GI
 - Volumetric lighting
 - SSR
 - Depth pre-pass - Make sure this can be toggled on and off as needed
 - HDR skybox, skylight stuff
 - Skin & vegetation shaders
 - Tesselation/displacement/parallax
 - Water
 - Fog
 - Motion blur
 - Per object shadows
 - Extend camera with shutter speed (motion blur), aperture size and focal distance (depth of field), exposure (HDR)
--------------------------- TEST -----------------------------

Test all APIs with new changes regarding depth buffer creation on windows