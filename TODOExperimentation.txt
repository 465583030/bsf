-------------------------
Study shadow rendering implementations

Test all APIs with new changes regarding depth buffer creation on windows
Document RenderTargetPool and potentially move it outside of BansheeRenderer
 - Quantize buffer sizes so they're divideable by 8
Implement light added/removed/updated in BansheeRenderer
Load up and set up a test-bed with Ribek's scene

Texture filtering changes:
 - Each sampler state gets a unique ID
 - I store this ID along with the sampler override
 - Every frame I run as pass over all renderable elements a check if their override
   sampler states match the original IDs, and recreate them if not (do this at start of rendering in renderAll core)
     - TODO - This can be potentially slower than needed. Optiomally I'd like to figure out a better way.
 - Whenever render settings are marked as dirty and filtering settings have changed run over all elements recreating their
   sampler state overrides
 - Issue with state caching: State caching doesn't work when deserializing

Rename BansheeRenderer to RenderBeast

Need cone to use when rendering spot light

Create a basic GBuffer - albedo, normal, depth
 - Using HDR formats where needed
 - Will need some kind of a pool that handles multiple viewports (each with its own gbuffer) and viewport resizing

Implement deferred rendering (just basic lambert shading for now, only point light)
 - Then convert to tiled rendering (will likely need normal deferred too as a fallback - and to be able to toggle and compare)

How will cameras interact with the renderer? The cameras currently available shouldn't have depth buffers
 - Need to modify RenderWindow so it doesn't create depth buffers
  - Find all places where I create windows and modify this
  - Modify render target creation in SceneWindow
 - What happens when a user creates a camera with a depth buffer?
   - Print out a warning and ignore it?
   - Or resolve the gbuffer into it? Probably this, as I want to be able to read the depth buffer from script code if needed
     - This still isn't perfect as I'd have duplicate buffers when using non-MSAA buffer that require no resolve

Render:
 - Iterate over all cameras and create their render queues, record whether a camera requires a gbuffer or not
    - How will "render()" callback signify whether they want a gbuffer or something else? 
     - Assume they need it? Probably - although it would be nice to be able to customize the render targets
	   of the render() calls. But I should probably think about that if it ever comes up, and implement it simply for now.
	 - Potentially restrict cameras to only non-multisampled RGBA8 targets. Then later we can add a special
	   mechanism for reading the depth buffer from sim thread(as well as reading other gbuffers)
	    - But I don't think this should be needed (It will probably be enough to signal to the rendering
		  thread to bind any one of those buffers, as we're only likely to use them from shaders. And shaders
		  can then even render them out to an outside target if needed.)
		- ALTHOUGH I do want to be able to set up custom render targets for the camera. So that custom scripts
		  and shaders can be executed as needed, possibly outputting multiple targets of various formats.
 - Sort cameras based on render targets and priority as we do now, additionally sort by whether they require gbuffer or not
 - Add new class RendererTargets
   - beginSceneRendering
   - endSceneRendering
   - resolve(RenderTarget)
  - Add new class RenderTargetPool
   - RTHandle handle = find(format, width, height, depth)
   - RTHandle keeps a shared ptr so that all cameras that use it can hold (once it runs out the render targets are freed)

 - Separate GUI rendering into a separate part to be rendered after gbuffer is resolved?

Will likely need an easy way to determine supported feature set (likely just depending on shader model)
Consider encapsulating shaders together with methods for setting their parameters (and possibly retrieving output)
 - So that external code doesn't need to know about its internal and do less work

-------------

Implement gamma correct rendering, HDR, tone mapping
 - Will likely need a simple framework for rendering full-screen effects
   (e.g. I will need to downsample scene to determine brightness here, but will
    also need that framework for all post-processing)

-------------

Implement shadows
 - Start with hard shadows
 - Move to PCF soft shadows (see if there's anything better)
 - Then cascaded maps

-------------

Later: 
 - Finish up all light types
 - Reflection probes
 - Proper PBR materials with reflection
 - Post-processing system - FXAA, SSAO, Color correction, Depth of field (Bokeh)
 - Forward rendering for transparent objects
 - Need a way to toggle texture filtering mode for all textures (Some kind of an override?)

-----------------

SECOND STAGE(S)
 - Occlusion
 - GI
 - Volumetric lighting
 - SSR
 - Depth pre-pass - Make sure this can be toggled on and off as needed
 - HDR skybox, skylight stuff

-----------------

THIRD STAGE(S)
 - Skin & vegetation shaders
 - Tesselation/displacement/parallax
 - Water
 - Fog
 - Motion blur
 - Per object shadows
 - Extend camera with shutter speed (motion blur), aperture size and focal distance (depth of field), exposure (HDR)